{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "ee13fff6-0d99-4c18-8c48-24727c5c3a1b",
   "metadata": {},
   "source": [
    "# MNIST Handwriten Digit Classification \n",
    "\n",
    "This is the main training file of the logistic/softmax classifier on MNIST."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "186557ec-9cc3-48b5-af0c-5fb14dd9a571",
   "metadata": {},
   "source": [
    "#### Import All Relevant Modules"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "667b1b73",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/var/folders/wb/ttr9x7pn27q1_rp5vtjfr0s00000gn/T/ipykernel_18109/4166587151.py:18: DeprecationWarning: the imp module is deprecated in favour of importlib and slated for removal in Python 3.12; see the module's documentation for alternative uses\n",
      "  import imp\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "<module 'train_utils' from '/Users/mghifary/Work/govtech/codes/AI/IF5171/deeplearning/src/train_utils.py'>"
      ]
     },
     "execution_count": 1,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import os\n",
    "import time as timer\n",
    "\n",
    "import torch\n",
    "from torch import nn\n",
    "from torch import optim\n",
    "from torch.utils.data import DataLoader\n",
    "\n",
    "from torchvision import datasets\n",
    "import torchvision.transforms as T\n",
    "\n",
    "## My own modules\n",
    "import viz_utils as vu\n",
    "import train_utils as tu\n",
    "import model_utils as mu\n",
    "###\n",
    "\n",
    "import imp\n",
    "imp.reload(mu)\n",
    "imp.reload(tu)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2ef2ec74-8682-48bd-b462-89da91db94e1",
   "metadata": {},
   "source": [
    "#### Constants"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "facfd8e9-ce46-4388-b3c6-c29b0c315195",
   "metadata": {},
   "outputs": [],
   "source": [
    "DATA_DIR = \"data\"\n",
    "MODEL_DIR = \"models\"\n",
    "\n",
    "EPOCHS = 10\n",
    "BATCH_SIZE = 64\n",
    "LEARNING_RATE = 1e-3\n",
    "\n",
    "DEVICE = \"cuda\" if torch.cuda.is_available() else \"cpu\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "060061b3-0cfc-48fb-af20-ea97bb828ae6",
   "metadata": {},
   "outputs": [
    {
     "ename": "AttributeError",
     "evalue": "module 'posixpath' has no attribute 'makedirs'",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mAttributeError\u001b[0m                            Traceback (most recent call last)",
      "Cell \u001b[0;32mIn [3], line 3\u001b[0m\n\u001b[1;32m      1\u001b[0m \u001b[38;5;66;03m## Create the directory to store the model if not exists\u001b[39;00m\n\u001b[1;32m      2\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m os\u001b[38;5;241m.\u001b[39mpath\u001b[38;5;241m.\u001b[39mexists(MODEL_DIR):\n\u001b[0;32m----> 3\u001b[0m     os\u001b[38;5;241m.\u001b[39mpath\u001b[38;5;241m.\u001b[39mmakedirs(MODEL_DIR)\n",
      "\u001b[0;31mAttributeError\u001b[0m: module 'posixpath' has no attribute 'makedirs'"
     ]
    }
   ],
   "source": [
    "## Create the directory to store the model if not exists\n",
    "if not os.path.exists(MODEL_DIR):\n",
    "    os.makedirs(MODEL_DIR)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7cc3c4cb-1a13-404e-8c6a-4714db75369a",
   "metadata": {},
   "source": [
    "#### Load MNIST dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d0baf274",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Load dataset\n",
    "training_data = datasets.MNIST(\n",
    "    root=DATA_DIR, \n",
    "    train=True, \n",
    "    download=True,\n",
    "    transform=T.ToTensor(), #convert to Tensor and normalize to (0, 1)\n",
    ")\n",
    "\n",
    "test_data = datasets.MNIST(\n",
    "    root=DATA_DIR,\n",
    "    train=False,\n",
    "    download=True,\n",
    "    transform=T.ToTensor(), #convert to Tensor and normalize to (0, 1)\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6c47154d",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Create data loaders\n",
    "train_dataloader = DataLoader(training_data, batch_size=BATCH_SIZE)\n",
    "test_dataloader = DataLoader(test_data, batch_size=BATCH_SIZE)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c727d4d7-22e3-4517-876e-83089cb4285c",
   "metadata": {},
   "outputs": [],
   "source": [
    "grid = vu.set_grid(train_dataloader.dataset.data, num_cells=56)\n",
    "vu.show(grid)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5bbed8ae-6bae-4b5e-a1c6-3f2a858b961a",
   "metadata": {},
   "outputs": [],
   "source": [
    "grid = vu.set_grid(test_dataloader.dataset.data, num_cells=56)\n",
    "vu.show(grid)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e4f50b08-5e55-4f89-bdaa-625298a3a056",
   "metadata": {},
   "source": [
    "#### Create the model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3d0da1b9-f567-40d8-aaf9-ab3a9869bb27",
   "metadata": {},
   "outputs": [],
   "source": [
    "print(f\"Using {DEVICE} device\")\n",
    "\n",
    "# Define model\n",
    "model = mu.SoftmaxClassifier(d_in=28*28, d_out=10).to(DEVICE)\n",
    "print(model)\n",
    "\n",
    "# Persistent file to store the model\n",
    "model_path = os.path.join(MODEL_DIR, \"softmax_mnist.pth\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "60205fbc-255e-43de-a90c-ce2464f076b3",
   "metadata": {},
   "outputs": [],
   "source": [
    "# print(f\"Using {DEVICE} device\")\n",
    "\n",
    "# # Define model\n",
    "# model = mu.MLP(d_in=28*28, d_out=10)\n",
    "# model = model.to(DEVICE)\n",
    "# print(model)\n",
    "\n",
    "# # Persistent file to store the model\n",
    "# model_path = os.path.join(MODEL_DIR, \"mlp_mnist.pth\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "fb3dfa4d-21e2-4fea-b1fb-990e739de02e",
   "metadata": {},
   "outputs": [],
   "source": [
    "# print(f\"Using {DEVICE} device\")\n",
    "\n",
    "# # Define model\n",
    "# model = mu.ConvNet(d_out=10).to(DEVICE)\n",
    "# print(model)\n",
    "\n",
    "# # Persistent file to store the model\n",
    "# model_path = os.path.join(MODEL_DIR, \"convnet_mnist_v3.pth\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "783ff064-3eb6-4f4d-bd6f-8a1d1aaf1119",
   "metadata": {},
   "source": [
    "#### Define the loss function and the optimizer"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a23af8b5-af51-450e-a20f-a1c871acce3a",
   "metadata": {},
   "outputs": [],
   "source": [
    "loss_fn = nn.CrossEntropyLoss()\n",
    "\n",
    "optimizer = optim.SGD(\n",
    "    model.parameters(), \n",
    "    lr=LEARNING_RATE\n",
    ")\n",
    "\n",
    "# optimizer = optim.Adam(\n",
    "#     model.parameters(), \n",
    "#     lr=LEARNING_RATE\n",
    "# )"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c666d623-ef4d-452c-84c9-22582ab0eeb4",
   "metadata": {},
   "source": [
    "#### Execute the training!"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9fc199f4-7d06-478b-bb50-c1c61e84545f",
   "metadata": {},
   "outputs": [],
   "source": [
    "for t in range(EPOCHS):\n",
    "    print(f\"Epoch {t+1} out of {EPOCHS}\\n ------------\")\n",
    "    \n",
    "    start = timer.time()\n",
    "    tu.train(train_dataloader, model, loss_fn, optimizer)\n",
    "    elapsed_time = timer.time() - start # this timing method ONLY works for CPU computation, not for GPU/cuda calls\n",
    "    print(f\" > Training time: {elapsed_time:>.2f} seconds\")\n",
    "    \n",
    "    tu.test(test_dataloader, model, loss_fn)\n",
    "    \n",
    "    # Save model\n",
    "    torch.save(model.state_dict(), model_path)\n",
    "    print(f\"Model {model_path} stored!\")\n",
    "    \n",
    "print(\"Done!\")"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
